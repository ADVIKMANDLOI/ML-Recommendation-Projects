# -*- coding: utf-8 -*-
"""Music recommendation model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EDRygcLriOJ9-jQeWhXg6QrbogJs8PzS

# Music Recommendation System
This project uses a dataset of user listening history to recommend songs using:

- Popularity-based recommendations
- Item similarity-based recommendations

Built as a Machine Learning major project.

Import libraries
"""

import pandas as pd
import numpy as np

"""Load and prepare data"""

triplet_df = pd.read_csv('/content/triplets_file.csv')
song_data = pd.read_csv('/content/song_data.csv')

print(triplet_df.shape)
print(song_data.shape)
triplet_df.head()

"""Merge dataset"""

# Merge the two datasets on song_id
song_data = song_data.drop_duplicates(['song_id'])
song_df = pd.merge(triplet_df, song_data, on='song_id', how='left')

# Drop rows with missing values
song_df = song_df.dropna(subset=['title', 'artist_name']).copy()

# Create a new combined feature
song_df['song'] = song_df['title'] + ' - ' + song_df['artist_name']

"""Subset and recent index for performance"""

# Limit to 50,000 rows for performance
song_df = song_df.head(50000)

# Reset index to avoid KeyError later
song_df = song_df.reset_index(drop=True)

# Remove rows with missing title or artist_name safely
song_df = song_df.dropna(subset=['title', 'artist_name']).copy()

# Now create the combined song field
song_df['song'] = song_df['title'] + ' - ' + song_df['artist_name']

"""Show most popular songs {Grouping}"""

song_grouped = song_df.groupby('song').agg({'listen_count': 'count'}).reset_index()
grouped_sum = song_grouped['listen_count'].sum()
song_grouped['percentage'] = (song_grouped['listen_count'] / grouped_sum) * 100

# Display top 10 popular songs
song_grouped.sort_values(['listen_count', 'song'], ascending=[False, True]).head(10)

"""Add recomender code

Create recomender.py
"""

code = """
import numpy as np
import pandas as pd

class popularity_recommender_py():
    def __init__(self):
        self.train_data = None
        self.user_id = None
        self.item_id = None
        self.popularity_recommendations = None

    def create(self, train_data, user_id, item_id):
        self.train_data = train_data
        self.user_id = user_id
        self.item_id = item_id

        train_data_grouped = train_data.groupby([self.item_id]).agg({self.user_id: 'count'}).reset_index()
        train_data_grouped.rename(columns={self.user_id: 'score'}, inplace=True)

        train_data_sort = train_data_grouped.sort_values(['score', self.item_id], ascending=[False, True])
        train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=False, method='first')

        self.popularity_recommendations = train_data_sort

    def recommend(self, user_id):
        user_recommendations = self.popularity_recommendations.copy()
        user_recommendations['user_id'] = user_id
        columns = ['user_id', self.item_id, 'score', 'Rank']
        return user_recommendations[columns].head(10)

class item_similarity_recommender_py():
    def __init__(self):
        self.train_data = None
        self.user_id = None
        self.item_id = None
        self.cooccurence_matrix = None

    def get_user_items(self, user):
        user_data = self.train_data[self.train_data[self.user_id] == user]
        return list(user_data[self.item_id].unique())

    def get_item_users(self, item):
        item_data = self.train_data[self.train_data[self.item_id] == item]
        return set(item_data[self.user_id].unique())

    def get_all_items_train_data(self):
        return list(self.train_data[self.item_id].unique())

    def construct_cooccurence_matrix(self, user_items, all_items):
        cooccurence_matrix = np.matrix(np.zeros((len(user_items), len(all_items))), float)
        for i in range(len(user_items)):
            users_i = self.get_item_users(user_items[i])
            for j in range(len(all_items)):
                users_j = self.get_item_users(all_items[j])
                intersection = users_i.intersection(users_j)
                if len(intersection) != 0:
                    cooccurence_matrix[i, j] = float(len(intersection)) / (len(users_i) + len(users_j) - len(intersection))
                else:
                    cooccurence_matrix[i, j] = 0
        return cooccurence_matrix

    def generate_top_recommendations(self, user, cooccurence_matrix, all_items, user_items):
        user_sim_scores = cooccurence_matrix.sum(axis=0) / float(cooccurence_matrix.shape[0])
        user_sim_scores = np.array(user_sim_scores)[0].tolist()
        sort_index = sorted(((e, i) for i, e in enumerate(user_sim_scores)), reverse=True)

        recommendations = []
        rank = 1
        for score, i in sort_index:
            if not np.isnan(score) and all_items[i] not in user_items and rank <= 10:
                recommendations.append([user, all_items[i], score, rank])
                rank += 1
        return pd.DataFrame(recommendations, columns=['user_id', 'song', 'score', 'rank'])

    def create(self, train_data, user_id, item_id):
        self.train_data = train_data
        self.user_id = user_id
        self.item_id = item_id

    def recommend(self, user):
        user_items = self.get_user_items(user)
        all_items = self.get_all_items_train_data()
        cooccurence_matrix = self.construct_cooccurence_matrix(user_items, all_items)
        return self.generate_top_recommendations(user, cooccurence_matrix, all_items, user_items)

    def get_similar_items(self, item_list):
        all_items = self.get_all_items_train_data()
        cooccurence_matrix = self.construct_cooccurence_matrix(item_list, all_items)
        return self.generate_top_recommendations('', cooccurence_matrix, all_items, item_list)
"""

with open("Recommenders.py", "w") as f:
    f.write(code)

"""Import and Run popularity recomender"""

import Recommenders as Recommenders

user_id = song_df['user_id'][5]  # Select any user

pr = Recommenders.popularity_recommender_py()
pr.create(song_df, 'user_id', 'song')
pr.recommend(user_id)

"""Run item similarity recommender"""

ir = Recommenders.item_similarity_recommender_py()
ir.create(song_df, 'user_id', 'song')

# User's song history
user_items = ir.get_user_items(user_id)
for song in user_items:
    print(song)

# Recommendations based on history
ir.recommend(user_id)

# Similar songs
ir.get_similar_items(['Use Somebody - Kings Of Leon'])

"""Based on selected song provide recommendation"""

ir.get_similar_items(['Oliver James - Fleet Foxes', 'The End - Pearl Jam'])

"""Recommendation for another song"""

ir.get_similar_items(['Use Somebody - Kings Of Leon'])

"""## Conclusion
- Popularity model gives general trending songs.
- Item similarity model gives personalized recommendations based on user listening history.
"""